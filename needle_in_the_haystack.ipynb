{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Needle in a Haystack Problem**  \n",
    "### **Semantic Search with OpenAI LLM**\n",
    "\n",
    "**Author**: [Shantanu Borkar](www.linkedin.com/in/shantanubkr)\n",
    "\n",
    "**Reviewer**: [Sarvesh Bhujle](https://www.linkedin.com/in/sarvesh-bhujle-78701231b/)\n",
    "\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://miro.medium.com/v2/resize:fit:2000/1*aDcggCoq28DmWhin4W1vDA.jpeg\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "The **Needle in a Haystack Problem** is a semantic search program that uses OpenAI's GPT-4 to find the most relevant sentence from a \"haystack\" of abstract sentences based on a user-provided query (the \"needle\"). The results are neatly formatted in Markdown for clear, structured output, making it ideal for Jupyter Notebook environments or any interface supporting Markdown rendering.\n",
    "\n",
    "---\n",
    "\n",
    "## **Features**\n",
    "\n",
    "- **Semantic Search:** Matches sentences based on meaning rather than exact keywords.  \n",
    "- **Markdown Output:** Neatly structures query results using Markdown formatting for readability.  \n",
    "- **AI-powered Matching:** Utilizes GPT-4‚Äôs chat completion API for natural language processing.  \n",
    "- **Error Handling:** Includes fallback responses for unmatched queries.  \n",
    "\n",
    "---\n",
    "\n",
    "## **How It Works**\n",
    "\n",
    "1. **Environment Setup:**  \n",
    "   - Loads API keys using `dotenv`.  \n",
    "   - Configures OpenAI's GPT-4 for semantic search.  \n",
    "\n",
    "2. **Semantic Search:**  \n",
    "   - The `find_needle()` function constructs a prompt instructing GPT-4 to identify the most relevant sentence from the haystack based on the query.  \n",
    "   - The result is formatted in Markdown.  \n",
    "\n",
    "3. **Testing:**  \n",
    "   - A set of test queries (`test_needles`) is processed to check how well the model finds matches.  \n",
    "\n",
    "4. **Output:**  \n",
    "   - Results are displayed using Jupyter's `Markdown` formatting via the `IPython.display` module.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1Ô∏è‚É£ Environment Setup**\n",
    "\n",
    "### **Step 1: Install Dependencies**  \n",
    "\n",
    "You need two main libraries:\n",
    "- **openai** ‚Äî to use GPT-4 for semantic search.  \n",
    "- **python-dotenv** ‚Äî to store your API key securely.\n",
    "\n",
    "Run this in your terminal:\n",
    "```bash\n",
    "pip install openai python-dotenv\n",
    "```\n",
    "\n",
    "### **Step 2: Add Your API Key**\n",
    "Create a `.env` file in the same folder as your script.\n",
    "\n",
    "Add your OpenAI API key like this:\n",
    "\n",
    "`.env` file:\n",
    "\n",
    "```bash \n",
    "OPENAI_API_KEY=your_api_key_here\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Import Libraries and Load API Key**\n",
    "\n",
    "Now, let's set up the environment and load the API key in your Python script:\n",
    "\n",
    "**‚úÖ What this does:**\n",
    "\n",
    "Loads your API key from the .env file.\n",
    "Configures the OpenAI client.\n",
    "Sets up Markdown display for clean output in Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set the API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2Ô∏è‚É£ Semantic Search Function**\n",
    "\n",
    "Now, let's create a function called `find_needle()`\n",
    "\n",
    "This function will:\n",
    "\n",
    "1. Take in a list of sentences (the haystack).\n",
    "\n",
    "2. Accept a user query (the needle).\n",
    "\n",
    "3. Ask GPT-4 to find the best match.\n",
    "\n",
    "4. Format the result in Markdown.\n",
    "\n",
    "**‚úÖ Explanation:**\n",
    "\n",
    "- The prompt tells GPT-4:\n",
    "\n",
    "    - Find the most relevant sentence from the haystack.\n",
    "\n",
    "    - Format the output using Markdown.\n",
    "\n",
    "- If no match is found, it responds with:\n",
    "\n",
    "- \"No match found.\"\n",
    "\n",
    "- The function returns the AI's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_needle(haystack, needle):\n",
    "    prompt = f\"\"\"\n",
    "    You are an advanced AI skilled in semantic search. Your task is to find the most relevant sentence from the provided haystack that best matches the given query, even if the match is approximate.\n",
    "\n",
    "    Format the output in Markdown with the following structure:\n",
    "\n",
    "    **Query:** \"{needle}\"\n",
    "\n",
    "    **Best Match:** \"[Insert best matching sentence from haystack]\"\n",
    "\n",
    "    If no match is found, respond with:\n",
    "\n",
    "    **Query:** \"{needle}\"\n",
    "\n",
    "    **\"No match found.\"**\n",
    "\n",
    "    Haystack:\n",
    "    {chr(10).join(haystack)}\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip() if response.choices else \"**Best Match:** \\\"No match found.\\\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3Ô∏è‚É£ Create the Haystack and Test Queries**\n",
    "\n",
    "Now, let's build our haystack (abstract sentences) and test needles (queries).\n",
    "\n",
    "**‚úÖ Why this setup?**\n",
    "\n",
    "- The haystack is a collection of abstract sentences ‚Äî not simple keyword matches.\n",
    "\n",
    "- The test needles include both valid and absurd queries, testing if GPT-4 can handle unexpected inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haystack = [\n",
    "    \"The clock forgot to chime, yet time marched on.\",\n",
    "    \"A cat danced in the moonlight, chasing shadows.\",\n",
    "    \"Silence echoed louder than the thunderstorm.\",\n",
    "    \"The invisible wind wrote secrets in the sand.\",\n",
    "    \"A broken compass pointed to nowhere and everywhere.\",\n",
    "    \"Colors argued on the painter's palette.\",\n",
    "    \"Dreams wandered through locked doors.\",\n",
    "    \"The echo of a whisper traveled farther than the shout.\",\n",
    "    \"An unread book knew all the answers.\",\n",
    "    \"Lightning remembered what the sky forgot.\",\n",
    "    \"The mountain moved, but the pebble stayed still.\",\n",
    "    \"A question mark floated above an empty chair.\",\n",
    "    \"Stars blinked, wondering who was watching.\",\n",
    "    \"The glass was both full and empty at once.\",\n",
    "    \"A shadow ran faster than the light chasing it.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4Ô∏è‚É£ Running the Tests**\n",
    "Now, let's test the function by running each query through the haystack.\n",
    "\n",
    "**‚úÖ Explanation:**\n",
    "\n",
    "- Loops through each needle (query).\n",
    "\n",
    "- Calls find_needle() to search for the most relevant haystack sentence.\n",
    "\n",
    "- Displays the result using Markdown for clean output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_needles = [\n",
    "    \"What did the wind write?\",\n",
    "    \"Which object defied direction?\",\n",
    "    \"Who knew the answers but remained silent?\",\n",
    "    \"What sound was louder than noise?\",\n",
    "    \"Which event happened despite no motion?\",\n",
    "    \"What did obama tell sarvesh?\"\n",
    "]\n",
    "\n",
    "\n",
    "for test_needle in test_needles:\n",
    "    match = find_needle(haystack, test_needle)\n",
    "    display(Markdown(match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ **Conclusion**\n",
    "\n",
    "Congratulations! üéâ  \n",
    "\n",
    "You've successfully built a **semantic search tool** powered by **OpenAI's GPT-4**.  \n",
    "\n",
    "\n",
    "In this journey, you learned how to:\n",
    "\n",
    "- **Set up your environment** ‚Äî installing dependencies and configuring API keys.  \n",
    "\n",
    "- **Create a haystack and needles** ‚Äî designing abstract sentences and queries for testing.  \n",
    "\n",
    "- **Implement semantic search** ‚Äî using GPT-4 to find the most relevant matches.  \n",
    "\n",
    "- **Handle errors and no-match cases** ‚Äî ensuring your program responds gracefully.  \n",
    "\n",
    "- **Customize and expand** ‚Äî adding your own haystacks, queries, and AI models.  \n",
    "\n",
    "\n",
    "This is just the beginning! üöÄ  \n",
    "\n",
    "You can now enhance your tool by:\n",
    "\n",
    "- Adding **confidence scores** for matches.  \n",
    "\n",
    "- Implementing **similarity thresholds** ‚Äî only showing results above a certain match level.\n",
    "\n",
    "- Building a simple **web interface** ‚Äî using **Flask** or **Streamlit** to let others test your app.\n",
    "\n",
    "\n",
    "The possibilities are endless.  \n",
    "\n",
    "Remember: **Every great solution starts with asking the right questions.**  \n",
    "\n",
    "Happy coding! üí°‚ú®\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! üåê\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
