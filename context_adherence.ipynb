{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Relevance Evaluator\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://www.shutterstock.com/image-vector/concept-context-magnifying-glass-letters-600nw-2482176791.jpg\"> \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "## Description:\n",
    "\n",
    "This app analyzes AI-generated responses to determine their relevance to a given context. It assigns a score, provides insights, and ensures meaningful interactions.\n",
    "\n",
    "- Evaluates response relevance based on provided context. \n",
    "\n",
    "- Uses OpenAI‚Äôs models for scoring and reflection.  \n",
    "\n",
    "- Helps maintain accuracy and coherence in AI responses.  \n",
    "\n",
    "- Provides detailed feedback on context adherence.  \n",
    "\n",
    "- Includes robust error handling for reliability.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Installation\n",
    "\n",
    "This step installs dependencies from `requirements.txt` and checks for `OPENAI_API_KEY`.  \n",
    "\n",
    "If installation fails, it retries up to 3 times before exiting.  \n",
    "\n",
    "Once complete, it clears the output and prints a success message.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate: This block goes into every notebook.\n",
    "# It sets up the environment, installs the requirements, and checks for the required environment variables.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "requirements_installed = False\n",
    "max_retries = 3\n",
    "retries = 0\n",
    "REQUIRED_ENV_VARS = [\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installs the requirements from requirements.txt file\"\"\"\n",
    "    global requirements_installed, retries\n",
    "    if requirements_installed:\n",
    "        print(\"Requirements already installed.\")\n",
    "        return\n",
    "\n",
    "    print(\"Installing requirements...\")\n",
    "    install_status = os.system(\"pip install -r requirements.txt\")\n",
    "    if install_status == 0:\n",
    "        print(\"Requirements installed successfully.\")\n",
    "        requirements_installed = True\n",
    "    else:\n",
    "        print(\"Failed to install requirements.\")\n",
    "        if retries < max_retries:\n",
    "            print(\"Retrying...\")\n",
    "            retries += 1\n",
    "            return install_requirements()\n",
    "        exit(1)\n",
    "    return\n",
    "\n",
    "\n",
    "install_requirements()\n",
    "clear_output()\n",
    "print(\"üöÄ Setup complete. Continue to the next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Environment Variable Setup\n",
    "\n",
    "This step loads environment variables from `.env` using `dotenv`.  \n",
    "\n",
    "It checks if `OPENAI_API_KEY` is set; if missing, it exits.  \n",
    "\n",
    "After validation, it confirms successful setup.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    \"\"\"Sets up the environment variables\"\"\"\n",
    "\n",
    "    def check_env(env_var):\n",
    "        value = os.getenv(env_var)\n",
    "        if value is None:\n",
    "            print(f\"Please set the {env_var} environment variable.\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            print(f\"{env_var} is set.\")\n",
    "\n",
    "    load_dotenv(override=True, dotenv_path=\".env\")\n",
    "\n",
    "    variables_to_check = REQUIRED_ENV_VARS\n",
    "\n",
    "    for var in variables_to_check:\n",
    "        check_env(var)\n",
    "\n",
    "    print(\"Environment variables are set.\")\n",
    "\n",
    "\n",
    "setup_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Context Adherence Evaluation\n",
    "\n",
    "- This code initializes the OpenAI API using an API key stored in environment variables.  \n",
    "\n",
    "- It defines a `ContextAdherenceResult` model to structure the output, including a relevance score, a reflection on the response's alignment with the context, and any errors encountered.  \n",
    "\n",
    "- The `detect_context_adherence` function sends a prompt and context to OpenAI, retrieves a response,  \n",
    "and evaluates its adherence to the provided context.  \n",
    "\n",
    "If an error occurs during the process, it is caught and logged, and a default response is returned.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import traceback\n",
    "\n",
    "openai = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "class ContextAdherenceResult(BaseModel):\n",
    "    context_adherence_score: float\n",
    "    context_adherence_reflection: str\n",
    "    error: str\n",
    "\n",
    "\n",
    "DEFAULT_COMPLETION_MODEL = \"gpt-4o\"\n",
    "DEFAULT_DETECTION_MODEL = \"gpt-4o\"\n",
    "\n",
    "\n",
    "def detect_context_adherence(prompt: str, context: str) -> ContextAdherenceResult:\n",
    "    \"\"\"Detects if the completion is relevant to the context\n",
    "\n",
    "    Args:\n",
    "        prompt : str : The prompt to provide the model.\n",
    "        ontext : str : The context to provide the model.\n",
    "\n",
    "    Returns:\n",
    "        ContextAdherenceResult : The result of the context adherence detection.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=DEFAULT_COMPLETION_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant. Given a prompt and context, you should provide a response that is relevant to the context.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"Prompt: {prompt}\\nContext: {context}\"},\n",
    "            ],\n",
    "        )\n",
    "        completion = response.choices[0].message.content\n",
    "\n",
    "        response = openai.beta.chat.completions.parse(\n",
    "            model=DEFAULT_DETECTION_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"\"\"\n",
    "                        Detect the 'Context Adherence' of the completion.\n",
    "                        Provide a score between 0 and 1, where 0 means the completion is not relevant to the context and 1 means the completion is relevant to the context.\n",
    "                        Also provide a reflection on why the completion is or is not relevant to the context.\n",
    "                        Based on the provided context, provide the score based on the following criteria:\n",
    "                        - The completion is relevant to the context. [Available Points: 0.2]\n",
    "                        - The completion has facts or information that is related to the context. [Available Points: 0.2]\n",
    "                        - The completion is coherent and makes sense in the context. [Available Points: 0.2]\n",
    "                        - The completion is helpful and provides value to the context. [Available Points: 0.2]\n",
    "                        - The completion does not include made-up information or unrelated content. [Available Points: 0.2]\n",
    "\n",
    "                        The 'Available Points' are the maximum points that can be awarded for each criteria. The total score should be calculated based on the sum of the points awarded for each criteria.\n",
    "\n",
    "                    \"\"\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"Prompt: {prompt}\\nContext: {context}\\nCompletion: {completion}\",\n",
    "                },\n",
    "            ],\n",
    "            response_format=ContextAdherenceResult,\n",
    "        )\n",
    "        return response.choices[0].message.parsed\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return ContextAdherenceResult(\n",
    "            context_adherence_score=0,\n",
    "            context_adherence_reflection=\"\",\n",
    "            error=str(e),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Running Context Adherence Check\n",
    "\n",
    "- This code sets a prompt asking for a summary of the **Taj Mahal** and provides a context about Jimon, a software engineer who proposed to his wife at the Taj Mahal.  \n",
    "\n",
    "- It then calls `detect_context_adherence` to check how well a generated response aligns with the given context.  \n",
    "\n",
    "- Finally, it prints the context adherence score and a reflection on the relevance of the response.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Provide a summary about the Taj Mahal.\"\n",
    "\n",
    "context = \"\"\"\n",
    "Jimon is a software engineer who has been working in the tech industry for over 10 years. He has experience in developing web applications, mobile applications, and cloud services. He is passionate about learning new technologies and enjoys working on challenging projects. In his free time, he likes to travel and explore new places. He is also an avid reader and enjoys reading books on technology and science fiction.\n",
    "Jimon graduated with a degree in Computer Science from a top university and has worked at several tech companies. He is known for his problem-solving skills and attention to detail. He is a team player and enjoys collaborating with others to build innovative solutions. Jimon is currently looking for new opportunities to work on exciting projects and expand his skill set.\n",
    "Jimon is married and has two children. He values work-life balance and believes in giving back to the community. He volunteers at local schools and mentors students who are interested in pursuing a career in technology. Jimon is a positive and optimistic person who believes in continuous improvement and personal growth.\n",
    "Jimon proposed to his wife at Taj Mahal.\n",
    "\"\"\"\n",
    "\n",
    "result = detect_context_adherence(prompt, context)\n",
    "\n",
    "print(f\"Context Adherence Score: {result.context_adherence_score}\")\n",
    "print(f\"Context Adherence Reflection: {result.context_adherence_reflection}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "- This app effectively evaluates context adherence by analyzing how well a generated response aligns with a given context.\n",
    "\n",
    "- It leverages OpenAI's language models to assess relevance, coherence, and factual accuracy.\n",
    "\n",
    "- The scoring system provides quantifiable insights into the quality of AI-generated responses.\n",
    "\n",
    "- Error handling ensures robustness, returning a default response in case of failures.\n",
    "\n",
    "- This tool can be useful for AI content validation, chatbots, and automated response systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Thank You for visiting The Hackers Playbook! üåê\n",
    "\n",
    "If you liked this research material;\n",
    "\n",
    "- [Subscribe to our newsletter.](https://thehackersplaybook.substack.com)\n",
    "\n",
    "- [Follow us on LinkedIn.](https://www.linkedin.com/company/the-hackers-playbook/)\n",
    "\n",
    "- [Leave a star on our GitHub.](https://www.github.com/thehackersplaybook)\n",
    "\n",
    "<div style=\"display:flex; align-items:center; padding: 50px;\">\n",
    "<p style=\"margin-right:10px;\">\n",
    "    <img height=\"200px\" style=\"width:auto;\" width=\"200px\" src=\"https://avatars.githubusercontent.com/u/192148546?s=400&u=95d76fbb02e6c09671d87c9155f17ca1e4ef8f21&v=4\"> \n",
    "</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
